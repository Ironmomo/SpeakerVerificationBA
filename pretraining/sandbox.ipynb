{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchaudio\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import argparse\n",
    "import psutil\n",
    "import GPUtil\n",
    "\n",
    "# Define the base path where your pickle file is located\n",
    "base_path2 = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/mask01-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli'\n",
    "base_path3 = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/mask01-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-20240412-172636'\n",
    "base_path1_at_same_time = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/mask01-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-20240413-164417'\n",
    "base_path_original = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-original-20240416-103133'\n",
    "base_path_shuffled = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-shuffled-20240416-102831'\n",
    "path_original_3 = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-original-20240418-211014'\n",
    "path_original_correctMean = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-20240501-162648-original-base-f128-t2-b48-lr1e-4-m390-pretrain_joint-asli'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full path to the 'args.pkl' file\n",
    "args_file_path2 = os.path.join(path_original_3, 'args.pkl')\n",
    "\n",
    "# Load the arguments from the pickle file\n",
    "with open(args_file_path2, 'rb') as f:\n",
    "    args2 = pickle.load(f)\n",
    "\n",
    "# Convert the Namespace to a dictionary if it is of that type\n",
    "if isinstance(args2, argparse.Namespace):\n",
    "    args_dict2 = vars(args2)\n",
    "else:\n",
    "    print(\"The loaded 'args' object is not an argparse.Namespace. Its type is:\", type(args2))\n",
    "    exit()\n",
    "\n",
    "# Determine the maximum width of the argument names for alignment\n",
    "max_key_length = max(len(key) for key in args_dict2.keys())\n",
    "\n",
    "# Print the arguments in a structured table format\n",
    "print(f\"{'Argument':<{max_key_length}} | Value\")\n",
    "print(\"-\" * (max_key_length + 3) + \"+\" + \"-\" * 30)  # Adjust 30 if you expect wider values\n",
    "\n",
    "for key, value in args_dict2.items():\n",
    "    print(f\"{key:<{max_key_length}} | {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Epochs, Iterations and Time Required"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the time required for training the model with 2 and 3 GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open progress files\n",
    "with open(os.path.join(base_path2, 'progress.pkl'), 'rb') as f:\n",
    "    progress2 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(base_path3, 'progress.pkl'), 'rb') as f:\n",
    "    progress3 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(base_path_original, 'progress.pkl'), 'rb') as f:\n",
    "    progress_original = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(base_path_shuffled, 'progress.pkl'), 'rb') as f:\n",
    "    progress_shuffled = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_original_3, 'progress.pkl'), 'rb') as f:\n",
    "    progress_original_3 = pickle.load(f)\n",
    "\n",
    "with open(os.path.join(path_original_correctMean, 'progress.pkl'), 'rb') as f:\n",
    "    progress_original_correctMean = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the iteration (is at the second position in the list of progress)\n",
    "iteration2 = np.array([x[1] for x in progress2])\n",
    "iteration3 = np.array([x[1] for x in progress3])\n",
    "iteration_original = np.array([x[1] for x in progress_original])\n",
    "iteration_shuffled = np.array([x[1] for x in progress_shuffled])\n",
    "iter_original = np.array([x[1] for x in progress_original_3])\n",
    "iter_original_correctMean = np.array([x[1] for x in progress_original_correctMean])*2\n",
    "\n",
    "# get time (is at the fourth position in the list of progress)\n",
    "time2 = np.array([x[3] for x in progress2])\n",
    "time3 = np.array([x[3] for x in progress3])\n",
    "time_original = np.array([x[3] for x in progress_original])\n",
    "time_shuffled = np.array([x[3] for x in progress_shuffled])\n",
    "time_orig = np.array([x[3] for x in progress_original_3])\n",
    "time_original_correctMean = np.array([x[3] for x in progress_original_correctMean])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate total time required for all 800k iterations based on the number of iterations and the time per iteration\n",
    "n_iterations = 800000\n",
    "time_per_iteration2 = time2[10] / iteration2[10]\n",
    "time_per_iteration3 = time3[10] / iteration3[10]\n",
    "time_per_iteration_original = time_original[-1] / iteration_original[-1]\n",
    "time_per_iteration_shuffled = time_shuffled[-1] / iteration_shuffled[-1]\n",
    "time_per_iter_orig = time_orig[-1] / iter_original[-1]\n",
    "time_per_iter_orig_correctMean = time_original_correctMean[-1] / iter_original_correctMean[-1]\n",
    "\n",
    "total_time2 = time_per_iteration2 * n_iterations\n",
    "total_time3 = time_per_iteration3 * n_iterations\n",
    "total_time_original = time_per_iteration_original * n_iterations\n",
    "total_time_shuffled = time_per_iteration_shuffled * n_iterations\n",
    "total_time_orig = time_per_iter_orig * n_iterations\n",
    "total_time_orig_correctMean = time_per_iter_orig_correctMean * n_iterations/2\n",
    "\n",
    "print(f\"Total time for 2 GPUs: {total_time2/3600:.2f} hours\")\n",
    "print(f\"Total time for 3 GPUs: {total_time3/3600:.2f} hours\")\n",
    "print(f\"Total time for original: {total_time_original/3600:.2f} hours\")\n",
    "print(f\"Total time for shuffled: {total_time_shuffled/3600:.2f} hours\")\n",
    "print(f\"Total time for original 3 PGUs: {total_time_orig/3600:.2f} hours\")\n",
    "print(f\"Total time for original correctMean: {total_time_orig_correctMean/3600:.2f} hours\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot iter vs time all in one plot\n",
    "plt.plot(iteration2, time2, label='2 GPUs')\n",
    "plt.plot(iteration3, time3, label='3 GPUs')\n",
    "plt.plot(iteration_original, time_original, label='original')\n",
    "plt.plot(iteration_shuffled, time_shuffled, label='shuffled')\n",
    "plt.plot(iter_original, time_orig, label='original 3 GPUs')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Time [s]')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full path to the 'result.csv' file\n",
    "result_file_path3 = os.path.join(base_path3, 'result.csv')\n",
    "\n",
    "# Load the result from the csv file\n",
    "result3 = np.genfromtxt(result_file_path3, delimiter=',')\n",
    "\n",
    "# Extract the columns from the result\n",
    "acc_train3 = result3[:, 0] # The first column\n",
    "loss_train3 = result3[:, 1] # The second column\n",
    "acc_eval3 = result3[:, 2] # The third column\n",
    "mse_eval3 = result3[:, 3] # The fourth column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the training and evaluation loss for the model trained with original and shuffled spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the full path to the 'result.csv' file\n",
    "result_file_path_original = os.path.join(base_path_original, 'result.csv')\n",
    "result_file_path_shuffled = os.path.join(base_path_shuffled, 'result.csv')\n",
    "\n",
    "# Load the result from the csv file\n",
    "result_original = np.genfromtxt(result_file_path_original, delimiter=',')\n",
    "result_shuffled = np.genfromtxt(result_file_path_shuffled, delimiter=',')\n",
    "print(\"shape of result_original: \", result_original.shape)\n",
    "print(\"shape of result_shuffled: \", result_shuffled.shape)\n",
    "\n",
    "# Extract the columns from the result\n",
    "\n",
    "acc_train_original = result_original[:, 0] # The first column\n",
    "loss1_train_original = result_original[:, 1] # The second column\n",
    "loss2_train_original = result_original[:, 2] # The third column\n",
    "acc_eval_original = result_original[:, 3] # The fourth column\n",
    "loss1_eval_original = result_original[:, 4] # The fifth column\n",
    "loss2_eval_original = result_original[:, 5] # The sixth column\n",
    "\n",
    "acc_train_shuffled = result_shuffled[:, 0] # The first column\n",
    "loss1_train_shuffled = result_shuffled[:, 1] # The second column\n",
    "loss2_train_shuffled = result_shuffled[:, 2] # The third column\n",
    "acc_eval_shuffled = result_shuffled[:, 3] # The fourth column\n",
    "loss1_eval_shuffled = result_shuffled[:, 4] # The fifth column\n",
    "loss2_eval_shuffled = result_shuffled[:, 5] # The sixth column\n",
    "\n",
    "learning_rate_original = result_original[:, 6] # The seventh column\n",
    "learning_rate_shuffled = result_shuffled[:, 6] # The seventh column\n",
    "\n",
    "\n",
    "# Define the format for each column\n",
    "header_format = \" {:>5}  | {:<10} | {:<10} | {:<10} | {:<10} | {:<10} | {:<10}\"\n",
    "row_format = \"{:>5}k  | {:<10.5f} | {:<10.5f} | {:<10.5f} | {:<10.5f} | {:<10.5f} | {:<10.5f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Orignal\n",
    "print(\"Original Spectrograms:\")\n",
    "print(\"-\" * 86)\n",
    "print(header_format.format(\"iter\", \"acc_train\", \"loss1_tr\", \"loss2_tr\", \"acc_ev\", \"loss1_ev\", \"loss2_ev\"))\n",
    "print(\"-\" * 86)  # Adjust the total length to fit your headers and column data\n",
    "for i in range(len(acc_train_original)):\n",
    "    print(row_format.format(iteration_original[i]/1e3, acc_train_original[i], loss1_train_original[i], loss2_train_original[i], acc_eval_original[i], loss1_eval_original[i], loss2_eval_original[i]))\n",
    "print(\"-\" * 86 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffled\n",
    "print(\"Shuffled Spectrograms:\")\n",
    "print(\"-\" * 86)\n",
    "print(header_format.format(\"iter\", \"acc_train\", \"loss1_tr\", \"loss2_tr\", \"acc_ev\", \"loss1_ev\", \"loss2_ev\"))\n",
    "print(\"-\" * 86)  # Adjust the total length to fit your headers and column data\n",
    "for i in range(len(acc_train_shuffled)):\n",
    "    print(row_format.format(iteration_shuffled[i]/1e3, acc_train_shuffled[i], loss1_train_shuffled[i], loss2_train_shuffled[i], acc_eval_shuffled[i], loss1_eval_shuffled[i], loss2_eval_shuffled[i]))\n",
    "print(\"-\" * 86 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_gong_path = '/home/bosfab01/SpeakerVerificationBA/pretraining/result_gong.csv'\n",
    "result_original_path = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-original-20240416-103133/result.csv'\n",
    "result_shuffled_path = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-shuffled-20240416-102831/result.csv'\n",
    "result_3GPU_path = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/mask01-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-20240412-172636/result.csv'\n",
    "result_original_3GPU_path = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-base-f128-t2-b24-lr1e-4-m400-pretrain_joint-asli-original-20240418-211014/result.csv'\n",
    "result_original_correctMean_path = '/home/bosfab01/SpeakerVerificationBA/pretraining/exp/pretrained-20240501-162648-original-base-f128-t2-b48-lr1e-4-m390-pretrain_joint-asli/result.csv'\n",
    "\n",
    "result_gong = np.genfromtxt(result_gong_path, delimiter=',')\n",
    "result_original = np.genfromtxt(result_original_path, delimiter=',')\n",
    "result_shuffled = np.genfromtxt(result_shuffled_path, delimiter=',')\n",
    "result_3GPU = np.genfromtxt(result_3GPU_path, delimiter=',')\n",
    "result_original_3GPU = np.genfromtxt(result_original_3GPU_path, delimiter=',')\n",
    "result_original_correctMean = np.genfromtxt(result_original_correctMean_path, delimiter=',')\n",
    "\n",
    "# print shapes of the arrays\n",
    "print(\"shape of result_gong: \", result_gong.shape)\n",
    "print(\"shape of result_original: \", result_original.shape)\n",
    "print(\"shape of result_shuffled: \", result_shuffled.shape)\n",
    "print(\"shape of result_3GPU: \", result_3GPU.shape)\n",
    "print(\"shape of result_original_3GPU: \", result_original_3GPU.shape)\n",
    "print(\"shape of result_original_correctMean: \", result_original_correctMean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to return columns of a numpy array\n",
    "def get_column(array):\n",
    "    for i in range(array.shape[1]):\n",
    "        yield array[:, i]\n",
    "\n",
    "acc_tr_gong, loss_tr_gong, acc_ev_gong, mse_ev_gong, lr_gong = get_column(result_gong)\n",
    "acc_tr_3GPU, loss_tr_3GPU, acc_ev_3GPU, mse_ev_3GPU, _ = get_column(result_3GPU)\n",
    "acc_tr_original, loss1_tr_original, loss2_tr_original, acc_ev_original, loss1_ev_original, loss2_ev_original, _ = get_column(result_original)\n",
    "acc_tr_shuffled, loss1_tr_shuffled, loss2_tr_shuffled, acc_ev_shuffled, loss1_ev_shuffled, loss2_ev_shuffled, _ = get_column(result_shuffled)\n",
    "acc_tr_original_3GPU, loss1_tr_original_3GPU, loss2_tr_original_3GPU, acc_ev_original_3GPU, loss1_ev_original_3GPU, loss2_ev_original_3GPU, lr_original_3GPU = get_column(result_original_3GPU)\n",
    "acc_tr_original_correctMean, loss1_tr_original_correctMean, loss2_tr_original_correctMean, acc_ev_original_correctMean, loss1_ev_original_correctMean, loss2_ev_original_correctMean, lr_original_correctMean = get_column(result_original_correctMean)\n",
    "\n",
    "iteration_gong = np.arange(1, len(acc_tr_gong)+1) * 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all the stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axs = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "axs[0, 0].plot(iteration_gong[:len(acc_tr_original_3GPU)+5]/1e3, acc_tr_gong[:len(acc_tr_original_3GPU)+5], label='gong')\n",
    "axs[0, 0].plot(iteration3[:len(acc_tr_original_3GPU)+5]/1e3, acc_tr_3GPU[:len(acc_tr_original_3GPU)+5], label='original 1024')\n",
    "axs[0, 0].plot(iter_original_correctMean/1e3, acc_tr_original_correctMean, label='original correctMean')\n",
    "# axs[0, 0].plot(iteration_original/1e3, acc_tr_original, label='original')\n",
    "# axs[0, 0].plot(iteration_shuffled/1e3, acc_tr_shuffled, label='shuffled')\n",
    "axs[0, 0].plot(iter_original/1e3, acc_tr_original_3GPU, label='original 998')\n",
    "#axs[0, 0].set_title('Accuracy Training')\n",
    "#axs[0, 0].set_xticks(np.arange(0, len(acc_tr_original)+5, 1))\n",
    "axs[0, 0].set_xlabel('Iteration [k]')\n",
    "axs[0, 0].set_ylabel('Accuracy Training')\n",
    "axs[0, 0].legend()\n",
    "axs[0, 0].grid()\n",
    "\n",
    "\n",
    "axs[0, 1].plot(iteration_gong[:len(acc_tr_original_3GPU)+5]/1e3, loss_tr_gong[:len(acc_tr_original_3GPU)+5], label='gong')\n",
    "axs[0, 1].plot(iteration3[:len(acc_tr_original_3GPU)+5]/1e3, loss_tr_3GPU[:len(acc_tr_original_3GPU)+5], label='original 1024')\n",
    "axs[0, 1].plot(iter_original_correctMean/1e3, loss1_tr_original_correctMean+10*loss2_tr_original_correctMean, label='original correctMean')\n",
    "# axs[0, 1].plot(iteration_original/1e3, loss1_tr_original+10*loss2_tr_original, label='original')\n",
    "# axs[0, 1].plot(iteration_shuffled/1e3, loss1_tr_shuffled+10*loss2_tr_shuffled, label='shuffled')\n",
    "axs[0, 1].plot(iter_original/1e3, loss1_tr_original_3GPU+10*loss2_tr_original_3GPU, label='original 998')\n",
    "#axs[0, 1].set_title('Loss Training')\n",
    "#axs[0, 1].set_xticks(np.arange(0, len(acc_tr_original)+5, 1))\n",
    "axs[0, 1].set_xlabel('Iteration [k]')\n",
    "axs[0, 1].set_ylabel('Loss Training')\n",
    "axs[0, 1].legend()\n",
    "axs[0, 1].grid()\n",
    "\n",
    "axs[1, 0].plot(iteration_gong[:len(acc_tr_original_3GPU)+5]/1e3, acc_ev_gong[:len(acc_tr_original_3GPU)+5], label='gong')\n",
    "axs[1, 0].plot(iteration3[:len(acc_tr_original_3GPU)+5]/1e3, acc_ev_3GPU[:len(acc_tr_original_3GPU)+5], label='original 1024')\n",
    "axs[1, 0].plot(iter_original_correctMean/1e3, acc_ev_original_correctMean, label='original correctMean')\n",
    "# axs[1, 0].plot(iteration_original/1e3, acc_ev_original, label='original')\n",
    "# axs[1, 0].plot(iteration_shuffled/1e3, acc_ev_shuffled, label='shuffled')\n",
    "axs[1, 0].plot(iter_original/1e3, acc_ev_original_3GPU, label='original 998')\n",
    "#axs[1, 0].set_title('Accuracy Evaluation')\n",
    "#axs[1, 0].set_xticks(np.arange(0, len(acc_tr_original)+5, 1))\n",
    "axs[1, 0].set_xlabel('Iteration [k]')\n",
    "axs[1, 0].set_ylabel('Accuracy Evaluation')\n",
    "axs[1, 0].legend()\n",
    "axs[1, 0].grid()\n",
    "\n",
    "axs[1, 1].plot(iteration_gong[:len(acc_tr_original_3GPU)+5]/1e3, mse_ev_gong[:len(acc_tr_original_3GPU)+5], label='gong')\n",
    "axs[1, 1].plot(iteration3[:len(acc_tr_original_3GPU)+5]/1e3, mse_ev_3GPU[:len(acc_tr_original_3GPU)+5], label='original 1024')\n",
    "axs[1, 1].plot(iter_original_correctMean/1e3, loss2_ev_original_correctMean, label='original correctMean')\n",
    "# axs[1, 1].plot(iteration_original/1e3, loss2_ev_original, label='original')\n",
    "# axs[1, 1].plot(iteration_shuffled/1e3, loss2_ev_shuffled, label='shuffled')\n",
    "axs[1, 1].plot(iter_original/1e3, loss2_ev_original_3GPU, label='original 998')\n",
    "#axs[1, 1].set_title('MSE Evaluation')\n",
    "#axs[1, 1].set_xticks(np.arange(0, len(acc_tr_original)+5, 1))\n",
    "axs[1, 1].set_xlabel('Iteration [k]')\n",
    "axs[1, 1].set_ylabel('MSE Evaluation')\n",
    "axs[1, 1].legend()\n",
    "axs[1, 1].grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot learning rate on log scale\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.plot(iteration_original/1e3, learning_rate_original, label='original')\n",
    "ax.plot(iteration_shuffled/1e3, learning_rate_shuffled, label='shuffled')\n",
    "ax.plot(iter_original/1e3, lr_original_3GPU, label='original 998')\n",
    "ax.plot(iteration_gong/1e3, lr_gong, label='gong')\n",
    "ax.set_yscale('log')\n",
    "ax.set_xlabel('Iteration [k]')\n",
    "ax.set_ylabel('Learning Rate')\n",
    "ax.legend()\n",
    "ax.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(iteration_shuffled/1e3, loss2_ev_shuffled, label='shuffled')\n",
    "plt.plot(iteration_shuffled/1e3, loss1_ev_shuffled, label='shuffled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing the dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Navigate up one level to the 'pretraining' directory, where 'dataloader.py' is located\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### demonstration of mismatch between target length and input length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataloader.AudioDataset(\n",
    "        dataset_json_file='/home/bosfab01/SpeakerVerificationBA/data/audioset2M_librispeech960.json',\n",
    "        audio_conf={\n",
    "            'num_mel_bins': 128,\n",
    "            'target_length': 1024,\n",
    "            'freqm': 0,\n",
    "            'timem': 0,\n",
    "            'mixup': 0,\n",
    "            'dataset': 'asli',\n",
    "            'mean': -3.6925695,\n",
    "            'std': 4.020388,\n",
    "            'noise': False,\n",
    "            'mode': 'train',\n",
    "            'shuffle_frames': False\n",
    "        },\n",
    "        label_csv='/home/bosfab01/SpeakerVerificationBA/data/label_information.csv'\n",
    "    ),\n",
    "    batch_size=24,\n",
    "    shuffle=True,\n",
    "    num_workers=16,\n",
    "    pin_memory=True,\n",
    "    drop_last=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get one batch of data from the dataloader and display the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an iterator from the DataLoader\n",
    "data_iterator = iter(train_loader)\n",
    "\n",
    "# Fetch the first batch\n",
    "audio_input, labels = next(data_iterator)\n",
    "\n",
    "# Print out the details to see what the batch contains\n",
    "print(\"Audio input shape:\", audio_input.shape)\n",
    "print(\"Labels shape:\", labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the last 10 spectra of the first sample in the batch\n",
    "# this is to check if the number of frames matches the target_length\n",
    "\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 10))  # Generate 10 colors from the 'viridis' colormap\n",
    "\n",
    "for i in range(10, 0, -1):\n",
    "    markerline, stemlines, baseline = plt.stem(audio_input[0, -i, :], linefmt='-', basefmt=\" \")\n",
    "    plt.setp(stemlines, 'linewidth', 2, 'color', colors[10-i])  # Set the color and line width\n",
    "    plt.setp(markerline, 'marker', '')  # No marker at the end\n",
    "\n",
    "plt.legend([f'Spectrum {-i}' for i in range(10, 0, -1)])\n",
    "plt.xlabel('Frequency Bins')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.title('Spectra of the Last 10 Frames')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# Print the last spectrum of the first sample\n",
    "print(audio_input[0, -1, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusted function to plot a spectrogram with the correct orientation\n",
    "def plot_spectrogram(spectrogram, ax, title=\"Spectrogram\"):\n",
    "    # Transpose the spectrogram to align the axes correctly\n",
    "    ax.imshow(spectrogram.T.cpu().numpy(), aspect='auto', origin='lower', cmap='viridis')\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlim(0, spectrogram.shape[0])\n",
    "    ax.set_xlabel('Time Frames')\n",
    "    ax.set_ylabel('Mel Frequency Bins')\n",
    "\n",
    "for i in range(3):\n",
    "    fig, ax = plt.subplots(figsize=(10, 1.5))\n",
    "    plot_spectrogram(audio_input[i, :, :], ax, title=f'Spectrogram of sample {i}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
