# SpeakerVerificationBA

## Introduction

This GitHub repository is dedicated to exploring the application of transformer networks in the domain of Automatic Speaker Recognition (ASR). The project focuses on investigating whether transformer architectures can effectively capture and learn voice dynamics for speaker identification tasks.

## Getting Started
### Init
1. Clone the Repo:
```
git clone https://github.com/Ironmomo/SpeakerVerificationBA.git
git lfs fetch
```
2. It is recommended to use a venv:
```
python3 -m venv myEnv
source myEnv/bin/activate
```
3. Install requirements:
```
pip install -r requirements.txt
```
### Repository Structure
The repository is structured as follows:
```
â””â”€â”€ ğŸ“SpeakerVerificationBA
    â””â”€â”€ .gitignore
    â””â”€â”€ README.md
    â””â”€â”€ ğŸ“data
    â””â”€â”€ dataloader.py
    â””â”€â”€ ğŸ“finetuning
        â””â”€â”€ sandbox.ipynb
    â””â”€â”€ main.py
    â””â”€â”€ ğŸ“plots_and_audios
        â””â”€â”€ ğŸ“audios
        â””â”€â”€ audios_thesis.ipynb
        â””â”€â”€ ğŸ“plots
        â””â”€â”€ plots_thesis.ipynb
        â””â”€â”€ sandbox.ipynb
    â””â”€â”€ ğŸ“pretraining
        â””â”€â”€ ğŸ“exp
        â””â”€â”€ result_gong.csv
        â””â”€â”€ run.py
        â””â”€â”€ run_mask.sh
        â””â”€â”€ sandbox.ipynb
        â””â”€â”€ traintest.py
        â””â”€â”€ traintest_mask.py
        â””â”€â”€ ğŸ“utilities
            â””â”€â”€ __init__.py
            â””â”€â”€ stats.py
            â””â”€â”€ util.py
    â””â”€â”€ requirements.txt
    â””â”€â”€ ssast_model.py
    â””â”€â”€ ğŸ“utils
        â””â”€â”€ Audio_Augmentation_Creation.py
        â””â”€â”€ Audio_Dataset.py
        â””â”€â”€ Audio_Loading.py
        â””â”€â”€ Data_Preprocess_Parallel.py
        â””â”€â”€ ğŸ“data_downloading
            â””â”€â”€ load_data.sh
        â””â”€â”€ ğŸ“processing
            â””â”€â”€ dataloader_ast.py
            â””â”€â”€ get_norm_stats.py
            â””â”€â”€ progress_monitoring.py
```

## Data Handling
### Data Loading
We provide a script to download the librispeech dataset or the voxceleb 1&2 dataset. You can use the same script just specify *voxceleb* or *librispeech* as argument.\
e.g.  
```
./data/load_data.sh voxceleb # Downloads voxceleb dataset 1&2
```
The dataset will be stored at *data/<dataset>/* where every subdirectory contains audiofiles of one specific speaker.

### Data Preprocessing
We provide you with a script to preprocess the data for the model. As suggested in the SSAST paper the data will be cut/padded to .flac Audiosamples of 10 sec with a sampling rate of 16000. Beside that an *Augmentation.csv* gets created which keeps the path of the preprocessed audiofile and the speaker_id.
The script allows you to specify the path of the dataset relativ to *data/*. Keep in mind that the path provided should be the directory containing the speaker directories. If you are using our Data loading scrip it is straight forward.\
You have to set the destination directory for the preprocessed data. This allows you to merge different datasets into one directory which can then be further used to create an instance of Audio_Dataset.
e.g. 
```
# Preprocess librispeech and save preprocessed data to data/preprocessed
python3 utils/Data_preprocess -d librispeech -n preprocessed
```

### Load Data for Training and Evaluation
We are using Pytorch. Therefore we created a class called Audio_Dataset which inherits from Dataset. Create an instance of Audio_Dataset to provide the model with data. The class has been implemented in *utils/Audio_Dataset.py*
To create an instance provide the augmentation file which has been created when preprocessing the data.

### Example
1. Download librispeech using a terminal
 ```
 ./data/load_data.sh librispeech
 ```

2. Preprocess data and store it at data/preprocessed
  ```
  python3 utils/Data_Preprocess.py -d librispeech -n preprocessed
  ```
     
3. Work with preprocessed data in python
```python

  # Use preprocessed Data
  AUGMENTATION_FILE = os.path.join(os.getcwd(), 'data', 'preprocessed', 'augmentation.csv')

  # Create DataSet Instance     
  dataset = AudioDataset(AUGMENTATION_FILE)

  # Split dataset
  train_data, test_data = random_split(dataset, (0.8, 0.2))
  
  train_sampler = RandomSampler(train_data)

# Create DataLoader
  dataloader = DataLoader(
          train_data,
          batch_size=10,
          sampler=train_sampler
      )
```
